{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9753bb25-6ad9-4b67-ac8b-8f290c4c023d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Missing columns detected: ['Sentiment']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "\n",
       "                 Summary                                               Text  \n",
       "0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n",
       "1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  \"Delight\" says it all  This is a confection that has been around a fe...  \n",
       "3         Cough Medicine  If you are looking for the secret ingredient i...  \n",
       "4            Great taffy  Great taffy at a great price.  There was a wid...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"Reviews.csv\")\n",
    "\n",
    "#  Required columns\n",
    "required_columns = [\"Summary\", \"Text\", \"Sentiment\", \"ProductId\", \"UserId\", \"Time\"]\n",
    "missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "\n",
    "# Check for missing columns\n",
    "if missing_columns:\n",
    "    print(f\"Warning: Missing columns detected: {missing_columns}\")\n",
    "    for col in missing_columns:\n",
    "        if col == \"ProductId\":\n",
    "            df[\"ProductId\"] = \"Unknown\"\n",
    "        elif col == \"UserId\":\n",
    "            df[\"UserId\"] = \"Anonymous\"\n",
    "        elif col == \"Time\":\n",
    "            df[\"Time\"] = pd.Timestamp.now()  # Default to current timestamp\n",
    "else:\n",
    "    print(\" All required columns are present.\")\n",
    "\n",
    "# Display updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6a4fb880-21d5-4099-9ee4-00eedeca0ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No 'UserId' column found. Skipping anonymization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>User_Anon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "      <td>c41af2a35a6fecc95a3f04e642d2cb695a7f2e74b34961...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "      <td>08c528d7c4df2cf389546a0064b6958b87bdc0d9dd7982...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "      <td>eb57c172bde49a93ab76e46ff06486fc1247dedf280f03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "      <td>12cce69c69a5c69c25399b3bb1640f341d09392e1d842b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "      <td>332bafccefbfdf3f258f73b172a6d169473cbaf593b772...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId                      ProfileName  HelpfulnessNumerator  \\\n",
       "0   1  B001E4KFG0                       delmartian                     1   \n",
       "1   2  B00813GRG4                           dll pa                     0   \n",
       "2   3  B000LQOCH0  Natalia Corres \"Natalia Corres\"                     1   \n",
       "3   4  B000UA0QIQ                             Karl                     3   \n",
       "4   5  B006K2ZZ7K    Michael D. Bigham \"M. Wassir\"                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time                Summary  \\\n",
       "0                       1      5  1303862400  Good Quality Dog Food   \n",
       "1                       0      1  1346976000      Not as Advertised   \n",
       "2                       1      4  1219017600  \"Delight\" says it all   \n",
       "3                       3      2  1307923200         Cough Medicine   \n",
       "4                       0      5  1350777600            Great taffy   \n",
       "\n",
       "                                                Text  \\\n",
       "0  I have bought several of the Vitality canned d...   \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...   \n",
       "2  This is a confection that has been around a fe...   \n",
       "3  If you are looking for the secret ingredient i...   \n",
       "4  Great taffy at a great price.  There was a wid...   \n",
       "\n",
       "                                           User_Anon  \n",
       "0  c41af2a35a6fecc95a3f04e642d2cb695a7f2e74b34961...  \n",
       "1  08c528d7c4df2cf389546a0064b6958b87bdc0d9dd7982...  \n",
       "2  eb57c172bde49a93ab76e46ff06486fc1247dedf280f03...  \n",
       "3  12cce69c69a5c69c25399b3bb1640f341d09392e1d842b...  \n",
       "4  332bafccefbfdf3f258f73b172a6d169473cbaf593b772...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "#  Check if \"UserId\" exists and anonymize\n",
    "if \"UserId\" in df.columns:\n",
    "    try:\n",
    "        df[\"User_Anon\"] = df[\"UserId\"].apply(lambda x: hashlib.sha256(str(x).encode()).hexdigest())\n",
    "        df.drop(columns=[\"UserId\"], inplace=True)  # Remove original user data\n",
    "        print(\"User data anonymized successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during user anonymization: {e}\")\n",
    "else:\n",
    "    print(\" No 'UserId' column found. Skipping anonymization.\")\n",
    "\n",
    "# Display updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d08a4178-9099-4e43-ae6d-77dc64634e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>User_Anon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165257</td>\n",
       "      <td>B000EVG8J2</td>\n",
       "      <td>B. Miller \"pet person\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1268179200</td>\n",
       "      <td>Crunchy &amp; Good Gluten-Free Sandwich Cookies!</td>\n",
       "      <td>Having tried a couple of other brands of glute...</td>\n",
       "      <td>39b3cc85c365c0f25c5c2ea896e32f722bcf1f061bb827...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>231466</td>\n",
       "      <td>B0000BXJIS</td>\n",
       "      <td>Marty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1298937600</td>\n",
       "      <td>great kitty treats</td>\n",
       "      <td>My cat loves these treats. If ever I can't fin...</td>\n",
       "      <td>be145d5cd9482a5b9a1ed8210085a3b121035609d2e201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>427828</td>\n",
       "      <td>B008FHUFAU</td>\n",
       "      <td>Kenneth Shevlin</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1224028800</td>\n",
       "      <td>COFFEE TASTE</td>\n",
       "      <td>A little less than I expected.  It tends to ha...</td>\n",
       "      <td>8af2d023446033002adf5e957f2c107b3caed45e050994...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>433955</td>\n",
       "      <td>B006BXV14E</td>\n",
       "      <td>rareoopdvds</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1335312000</td>\n",
       "      <td>So the Mini-Wheats were too big?</td>\n",
       "      <td>First there was Frosted Mini-Wheats, in origin...</td>\n",
       "      <td>619eeee1c8befcd761df16908ae7af038ac34a667c5292...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70261</td>\n",
       "      <td>B007I7Z3Z0</td>\n",
       "      <td>Og8ys1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1334707200</td>\n",
       "      <td>Great Taste . . .</td>\n",
       "      <td>and I want to congratulate the graphic artist ...</td>\n",
       "      <td>654597f911702ccfe2cf61941d996e48f6fccf32dc0a06...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId             ProfileName  HelpfulnessNumerator  \\\n",
       "0  165257  B000EVG8J2  B. Miller \"pet person\"                     0   \n",
       "1  231466  B0000BXJIS                   Marty                     0   \n",
       "2  427828  B008FHUFAU         Kenneth Shevlin                     0   \n",
       "3  433955  B006BXV14E             rareoopdvds                     0   \n",
       "4   70261  B007I7Z3Z0                  Og8ys1                     0   \n",
       "\n",
       "   HelpfulnessDenominator  Score        Time  \\\n",
       "0                       0      5  1268179200   \n",
       "1                       0      5  1298937600   \n",
       "2                       2      3  1224028800   \n",
       "3                       1      2  1335312000   \n",
       "4                       2      5  1334707200   \n",
       "\n",
       "                                        Summary  \\\n",
       "0  Crunchy & Good Gluten-Free Sandwich Cookies!   \n",
       "1                            great kitty treats   \n",
       "2                                  COFFEE TASTE   \n",
       "3              So the Mini-Wheats were too big?   \n",
       "4                             Great Taste . . .   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Having tried a couple of other brands of glute...   \n",
       "1  My cat loves these treats. If ever I can't fin...   \n",
       "2  A little less than I expected.  It tends to ha...   \n",
       "3  First there was Frosted Mini-Wheats, in origin...   \n",
       "4  and I want to congratulate the graphic artist ...   \n",
       "\n",
       "                                           User_Anon  \n",
       "0  39b3cc85c365c0f25c5c2ea896e32f722bcf1f061bb827...  \n",
       "1  be145d5cd9482a5b9a1ed8210085a3b121035609d2e201...  \n",
       "2  8af2d023446033002adf5e957f2c107b3caed45e050994...  \n",
       "3  619eeee1c8befcd761df16908ae7af038ac34a667c5292...  \n",
       "4  654597f911702ccfe2cf61941d996e48f6fccf32dc0a06...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select only 750 reviews randomly\n",
    "df_sample = df.sample(n=750, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Display sample dataset\n",
    "df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef8d5bb0-b475-484d-a5fc-9c204245634d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sagemaker-\n",
      "[nltk_data]     user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Having tried a couple of other brands of glute...</td>\n",
       "      <td>tri coupl brand glutenfre sandwich cooki best ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My cat loves these treats. If ever I can't fin...</td>\n",
       "      <td>cat love treat ever cant find hous pop top bol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little less than I expected.  It tends to ha...</td>\n",
       "      <td>littl less expect tend muddi tast expect sinc ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First there was Frosted Mini-Wheats, in origin...</td>\n",
       "      <td>first frost miniwheat origin size frost miniwh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and I want to congratulate the graphic artist ...</td>\n",
       "      <td>want congratul graphic artist put entir produc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  \\\n",
       "0  Having tried a couple of other brands of glute...   \n",
       "1  My cat loves these treats. If ever I can't fin...   \n",
       "2  A little less than I expected.  It tends to ha...   \n",
       "3  First there was Frosted Mini-Wheats, in origin...   \n",
       "4  and I want to congratulate the graphic artist ...   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  tri coupl brand glutenfre sandwich cooki best ...  \n",
       "1  cat love treat ever cant find hous pop top bol...  \n",
       "2  littl less expect tend muddi tast expect sinc ...  \n",
       "3  first frost miniwheat origin size frost miniwh...  \n",
       "4  want congratul graphic artist put entir produc...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#  Download NLTK Stopwords\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "#  Function to Clean Text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove numbers\n",
    "    text = \" \".join([stemmer.stem(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "#  Apply Text Cleaning\n",
    "df_sample[\"Cleaned_Text\"] = df_sample[\"Text\"].apply(clean_text)\n",
    "\n",
    "#  Display Sample Data\n",
    "df_sample[[\"Text\", \"Cleaned_Text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2d0996f-9385-4c47-b683-a165e61b1a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AWS Comprehend Connected Successfully!\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "#  Connect to AWS Comprehend (Replace 'eu-west-2' with your AWS region)\n",
    "comprehend = boto3.client(service_name='comprehend', region_name='eu-west-2')\n",
    "\n",
    "print(\" AWS Comprehend Connected Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d18c334e-c5a2-4bc2-8902-b2b14b433731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Comprehend_Sentiment</th>\n",
       "      <th>Comprehend_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tri coupl brand glutenfre sandwich cooki best ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>{'Positive': 0.47346004843711853, 'Negative': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat love treat ever cant find hous pop top bol...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>{'Positive': 0.7705198526382446, 'Negative': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>littl less expect tend muddi tast expect sinc ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{'Positive': 0.04822135344147682, 'Negative': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first frost miniwheat origin size frost miniwh...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{'Positive': 0.23086786270141602, 'Negative': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want congratul graphic artist put entir produc...</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>{'Positive': 0.230007603764534, 'Negative': 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Cleaned_Text Comprehend_Sentiment  \\\n",
       "0  tri coupl brand glutenfre sandwich cooki best ...             POSITIVE   \n",
       "1  cat love treat ever cant find hous pop top bol...             POSITIVE   \n",
       "2  littl less expect tend muddi tast expect sinc ...              NEUTRAL   \n",
       "3  first frost miniwheat origin size frost miniwh...              NEUTRAL   \n",
       "4  want congratul graphic artist put entir produc...                MIXED   \n",
       "\n",
       "                                    Comprehend_Score  \n",
       "0  {'Positive': 0.47346004843711853, 'Negative': ...  \n",
       "1  {'Positive': 0.7705198526382446, 'Negative': 0...  \n",
       "2  {'Positive': 0.04822135344147682, 'Negative': ...  \n",
       "3  {'Positive': 0.23086786270141602, 'Negative': ...  \n",
       "4  {'Positive': 0.230007603764534, 'Negative': 0....  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_sentiment(text):\n",
    "    if text:\n",
    "        try:\n",
    "            response = comprehend.detect_sentiment(Text=text, LanguageCode='en')\n",
    "            return response['Sentiment'], response['SentimentScore']\n",
    "        except Exception as e:\n",
    "            print(f\" Error during Comprehend analysis: {e}\")\n",
    "            return \"ERROR\", {\"Positive\": 0, \"Negative\": 0, \"Neutral\": 0, \"Mixed\": 0}\n",
    "    return \"NO_TEXT\", {\"Positive\": 0, \"Negative\": 0, \"Neutral\": 0, \"Mixed\": 0}\n",
    "\n",
    "#  Apply Sentiment Analysis to Cleaned Text\n",
    "df_sample[['Comprehend_Sentiment', 'Comprehend_Score']] = df_sample['Cleaned_Text'].apply(analyze_sentiment).tolist()\n",
    "\n",
    "# Display Sentiment Results\n",
    "df_sample[['Cleaned_Text', 'Comprehend_Sentiment', 'Comprehend_Score']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "54285145-362d-4678-bec6-edd3c1b0db97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Comprehend_Sentiment</th>\n",
       "      <th>Sentiment_1_to_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tri coupl brand glutenfre sandwich cooki best ...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat love treat ever cant find hous pop top bol...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>littl less expect tend muddi tast expect sinc ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>first frost miniwheat origin size frost miniwh...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want congratul graphic artist put entir produc...</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>pleas add pineappl flavor packag lifesav fact ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>absolut love yorkshir tea glad avail amazon cu...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hard time find loos tea local abl order favori...</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>previous ive attempt recip white rice noodl ov...</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>make pancak waffl everi saturday morn kid simp...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lover coffe tri almost coffe product coffe pod...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>uk one popular chocol bar light honeycomb bar ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>daughter bought keurig coffe maker husband chr...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>compar flavor starbuck cost much less dont kno...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>simpli aw product taken market immedi absolut ...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>would give hot sauc best hot sauc ever made hu...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>luckili avail local got tri without order whol...</td>\n",
       "      <td>MIXED</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>oatmeal great eat almost everi morn brand stor...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>satin ice best tast fondant find market littl ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>bought year old dad seen commerci thought look...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Cleaned_Text Comprehend_Sentiment  \\\n",
       "0   tri coupl brand glutenfre sandwich cooki best ...             POSITIVE   \n",
       "1   cat love treat ever cant find hous pop top bol...             POSITIVE   \n",
       "2   littl less expect tend muddi tast expect sinc ...              NEUTRAL   \n",
       "3   first frost miniwheat origin size frost miniwh...              NEUTRAL   \n",
       "4   want congratul graphic artist put entir produc...                MIXED   \n",
       "5   pleas add pineappl flavor packag lifesav fact ...              NEUTRAL   \n",
       "6   absolut love yorkshir tea glad avail amazon cu...             POSITIVE   \n",
       "7   hard time find loos tea local abl order favori...                MIXED   \n",
       "8   previous ive attempt recip white rice noodl ov...                MIXED   \n",
       "9   make pancak waffl everi saturday morn kid simp...             POSITIVE   \n",
       "10  lover coffe tri almost coffe product coffe pod...              NEUTRAL   \n",
       "11  uk one popular chocol bar light honeycomb bar ...              NEUTRAL   \n",
       "12  daughter bought keurig coffe maker husband chr...             POSITIVE   \n",
       "13  compar flavor starbuck cost much less dont kno...             POSITIVE   \n",
       "14  simpli aw product taken market immedi absolut ...             NEGATIVE   \n",
       "15  would give hot sauc best hot sauc ever made hu...              NEUTRAL   \n",
       "16  luckili avail local got tri without order whol...                MIXED   \n",
       "17  oatmeal great eat almost everi morn brand stor...             POSITIVE   \n",
       "18  satin ice best tast fondant find market littl ...              NEUTRAL   \n",
       "19  bought year old dad seen commerci thought look...              NEUTRAL   \n",
       "\n",
       "    Sentiment_1_to_5  \n",
       "0                  2  \n",
       "1                  3  \n",
       "2                  3  \n",
       "3                  3  \n",
       "4                  3  \n",
       "5                  3  \n",
       "6                  4  \n",
       "7                  3  \n",
       "8                  3  \n",
       "9                  2  \n",
       "10                 3  \n",
       "11                 3  \n",
       "12                 2  \n",
       "13                 4  \n",
       "14                 4  \n",
       "15                 3  \n",
       "16                 3  \n",
       "17                 3  \n",
       "18                 3  \n",
       "19                 3  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def map_sentiment_score(sentiment, scores):\n",
    "    if sentiment == \"POSITIVE\":\n",
    "        return int(5 * scores[\"Positive\"])  # Scale Positive Score to 5\n",
    "    elif sentiment == \"NEGATIVE\":\n",
    "        return int(5 * scores[\"Negative\"])  # Scale Negative Score to 1\n",
    "    elif sentiment == \"NEUTRAL\":\n",
    "        return 3  # Keep neutral as 3\n",
    "    elif sentiment == \"MIXED\":\n",
    "        return 3  # Mixed sentiment is ambiguous\n",
    "    elif sentiment == \"NO_TEXT\":\n",
    "        return 0  # No text means no rating\n",
    "    elif sentiment == \"ERROR\":\n",
    "        return -1  # Error handling case\n",
    "    else:\n",
    "        return 0  # Default case\n",
    "\n",
    "# Convert AWS Sentiment Scores\n",
    "df_sample['Sentiment_1_to_5'] = df_sample.apply(lambda row: map_sentiment_score(row['Comprehend_Sentiment'], row['Comprehend_Score']), axis=1)\n",
    "\n",
    "#  Display Results\n",
    "df_sample[['Cleaned_Text', 'Comprehend_Sentiment', 'Sentiment_1_to_5']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e66d3e59-4ddc-4266-a83a-a853b4e3651e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Feature Matrix Shape: (750, 4730)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#  Initialize TF-IDF Vectorizer (limit to 5000 most important words)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "\n",
    "#  Transform text into TF-IDF vectors\n",
    "X_tfidf = vectorizer.fit_transform(df_sample[\"Cleaned_Text\"])\n",
    "\n",
    "#  Display shape of the TF-IDF feature matrix\n",
    "print(f\"TF-IDF Feature Matrix Shape: {X_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6401ffef-9c14-4f2a-bed3-bf30ce033154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Dataset Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Store ML Inputs (TF-IDF Features) and Labels (Sentiment Scores)\n",
    "X = X_tfidf  # ML Model Input (TF-IDF)\n",
    "y = df_sample[\"Sentiment_1_to_5\"]  # Target Labels (1-5 ratings)\n",
    "\n",
    "# Save Data for Training\n",
    "pickle.dump((X, y), open(\"ml_dataset.pkl\", \"wb\"))\n",
    "print(\"ML Dataset Saved Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3f16d78a-076d-4d14-a5fd-06480befcdc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set: 600 reviews\n",
      "Validation Set: 75 reviews\n",
      "Test Set: 75 reviews\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#  Split the data\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)  # 80% train, 20% temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # 10% val, 10% test\n",
    "\n",
    "#  Print Dataset Sizes using .shape[0]\n",
    "print(f\"Training Set: {X_train.shape[0]} reviews\")\n",
    "print(f\"Validation Set: {X_val.shape[0]} reviews\")\n",
    "print(f\"Test Set: {X_test.shape[0]} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b9e3a72c-661a-4d43-ab16-b0b7397afce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Na誰ve Bayes Accuracy: 0.6400\n",
      " SVM Accuracy: 0.6667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Train Na誰ve Bayes Model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "\n",
    "# Train Support Vector Machine (SVM) Model\n",
    "svm_model = SVC(kernel=\"linear\")\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "#  Evaluate Models\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "svm_accuracy = accuracy_score(y_test, y_pred_svm)\n",
    "\n",
    "print(f\" Na誰ve Bayes Accuracy: {nb_accuracy:.4f}\")\n",
    "print(f\" SVM Accuracy: {svm_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6fa2044a-cca3-464a-bed3-bd0efc39d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Model Selected: SVM\n"
     ]
    }
   ],
   "source": [
    "# Choose Best Model\n",
    "if nb_accuracy > svm_accuracy:\n",
    "    best_model = nb_model\n",
    "    model_name = \"Na誰ve Bayes\"\n",
    "else:\n",
    "    best_model = svm_model\n",
    "    model_name = \"SVM\"\n",
    "\n",
    "print(f\" Best Model Selected: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "23a77cd9-6ed7-40fa-96d2-c51e99c49164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Best Model (SVM) Saved Successfully!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "#  Save the best model\n",
    "with open(\"best_model.pkl\", \"wb\") as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "print(f\" Best Model ({model_name}) Saved Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "364bca45-5e59-4b86-b297-e20f38b826e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Predictions: [3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "with open(\"best_model.pkl\", \"rb\") as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "#  Test the loaded model on validation data\n",
    "sample_prediction = loaded_model.predict(X_val[:5])\n",
    "print(f\"Sample Predictions: {sample_prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6a46280d-26fa-466e-a9cf-f2d37edb4c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model 'sentiment-analysis-model-v5' is registered successfully!\n"
     ]
    }
   ],
   "source": [
    "#  Check if the model exists\n",
    "response = sagemaker.list_models()\n",
    "models = [model[\"ModelName\"] for model in response[\"Models\"]]\n",
    "\n",
    "if model_name in models:\n",
    "    print(f\" Model '{model_name}' is registered successfully!\")\n",
    "else:\n",
    "    print(f\" Model '{model_name}' is NOT found. Something went wrong.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd2d06a-2dad-4235-9e49-248df4444052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
